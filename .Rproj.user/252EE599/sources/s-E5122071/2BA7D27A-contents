

# Tuning parameters:
## Max_depth
##




# parameters
d <- 5 # covariate dimension
alpha <- 0.05  # coverage probability
lrnr <- Lrnr_gam$new()

lrnr <- Lrnr_sl$new(Stack$new(
  Lrnr_xgboost$new(max_depth = 3),
  Lrnr_xgboost$new(max_depth = 4),
  Lrnr_xgboost$new(max_depth = 5),
  Lrnr_xgboost$new(max_depth = 6),
  Lrnr_xgboost$new(max_depth = 7),
  Lrnr_xgboost$new(max_depth = 8),
  Lrnr_xgboost$new(max_depth = 9)
),
Lrnr_cv_selector$new(loss_squared_error))
lrnr <- Lrnr_gam$new()
# parameters
## max-depth: 1, 3, 5, 7, 9
## n_cal: 100, 300, 500, 750, 1000
#
# get data splits

d_list <- c(1, 5, 10)
depth_list <- c(2, 4, 6, 8, 10)
n_train_list <- c(100, 250, 500, 1000)
for(max_depth in depth_list) {
  for(n_train in n_train_list) {

  }
}

run_sim_once <- function(n_train, max_depth, d, alpha) {
  lrnr <- Lrnr_xgboost$new(max_depth = max_depth)

  data_list <- generate_data_splits(1000, 1000, 1000, d = d)
  data_train <- data_list$data_train; data_cal <- data_list$data_cal; data_test <- data_list$data_test
  X_train <- data_train$X; X_cal <- data_cal$X; X_test <- data_test$X
  Y_train <- data_train$Y; Y_cal <- data_cal$Y; Y_test <- data_test$Y

  # get predictor using learning algorithm specified by lrnr
  predictor <- train_predictor(X_train, Y_train, lrnr)

  plot(predictor(X_train), data_train$mu)
  #
  preds_bin <- do_conformal_calibration(X_cal, Y_cal, X_test, predictor, alpha = alpha, calibrator = binning_calibrator, nbin = 10)
  #preds_bin2 <- do_conformal_calibration(X_cal, Y_cal, X_test, predictor, alpha = alpha, calibrator = binning_calibrator, nbin = 50)
  preds_iso <- do_conformal_calibration(X_cal, Y_cal, X_test, predictor, alpha = alpha, calibrator = iso_calibrator)
  #preds_cond <- do_conformal_conditional(X_cal, Y_cal, X_test, predictor, alpha = alpha)
  preds_marg <- do_conformal_marginal(X_cal, Y_cal, X_test, predictor, alpha = alpha)

  preds_bin$method <- "binning"
  #preds_bin2$method <- "binning2"
  preds_iso$method <- "isotonic"
  #preds_cond$method <- "conditional"
  preds_marg$method <- "marginal"


  all_preds <- rbindlist(list(preds_bin, preds_iso, preds_marg))
  nmethod <- nrow(all_preds) / nrow(preds_bin)
  all_preds$Y <- rep(Y_test, nmethod)
  all_preds$Z1 <- rep(data_test$Z1, nmethod)
  all_preds$Z0 <- rep(data_test$Z0, nmethod)
  # Extract bins for differences in the conditional variance.
  sigma2 <- data_test$sigma2
  bins_hetero <- findInterval(sigma2, quantile(sigma2, seq(0, 1 , length = 6)), all.inside = TRUE)
  all_preds$bin <- rep(bins_hetero, nmethod)
  setkey(all_preds, method, bin)
  all_preds[, .(mean(Y >= lower & Y <= upper), mean(width)), by = c("method","bin")]

  all_preds[, .(mean(Y >= lower & Y <= upper), mean(width)), by = c("method")]


  out <- rbindlist(lapply(quantile(data_train$Y, seq(0.7,0.9, length = 10)), function(threshold) {
    treatment_rule <- function(f, lower, upper){
      # high risk, so only treat if above threshold.
      treatment <- 1*(upper <= threshold)
      return(treatment)
    }

    all_preds$A <- treatment_rule(all_preds$f, all_preds$lower, all_preds$upper)
    out <- all_preds[, mean(Z1 * A + Z0 * (1-A)), by = method]
    print(out)
    out$threshold <- threshold
    return(out)
  }))

  plot(out$threshold[out$method=="marginal"], out$V1[out$method=="marginal"], type = "l", col = "blue")

  lines(out$threshold[out$method=="isotonic"], out$V1[out$method=="isotonic"], col = "red")



  threshold_upper <- quantile(data_train$Y, 0.8)
  threshold_lower <- quantile(data_train$Y, 0.2)

  treatment_rule <- function(f, lower, upper){
    # high risk, so only treat if above threshold.
    treatment <- 1- 1*(lower >= threshold_lower) * 1 * (upper <= threshold_upper)
    return(treatment)
  }
  Ytrue <- data_test$Y

  all_preds$A <- treatment_rule(all_preds$f, all_preds$lower, all_preds$upper)
  #all_preds$Atrue <- rep(1*(data_test$Y <= threshold), 3)
  all_preds$Y <- rep(data_test$Y , 3)



  out <- all_preds[, mean((Z1 * A + Z0 * (1-A))), by = method]
}

